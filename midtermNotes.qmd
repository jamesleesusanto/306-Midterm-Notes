---
title: "Midterm Notes"
subtitle: "Datasci 306"
description: "Midterm Thursday 10/9 during lecture"
format: html
execute:
    warning: false
    message: false
---

```{r}
#library(tidyverse)
suppressPackageStartupMessages(suppressWarnings(library(tidyverse)))
library(dplyr)
library(ggplot2)
```

## Lecture 1: 8-26

```{r}
heights <- read_csv("https://ds306.org/data/survey1.csv")
glimpse(heights)
```

#### Vectors

```{r}
c(1,2,3)
```
```{r}
1:10
```
```{r}
c(1,2,3)[3]
```

#### Operations on Dataframes

```{r}
#help(glimpse)
glimpse(heights)
```
```{r}
#help(summary)
summary(heights)
```
```{r}
#df$colName
heights$`What is your height? (use whichever units you prefer)`
```

###### Renaming Columns

```{r}
#og colnames
colnames(heights)
#Rename Columns
colnames(heights) <- c("timestamp", "sex", "height")
glimpse(heights)
```

```{r}
ncol(heights)
nrow(heights)
```

```{r}
mean(c(1,2,3))
```

```{r}
#Will return 96.6379 - not under same unit (cm or in), 
#too high or too low
mean(heights$height)
```

```{r}
#Hist looks wierd b/c the diff in units
hist(heights$height)
```

```{r}
#Reassign so can type faster
h <- heights$height
```

```{r}
#return a vector of bools
h < 200
```

```{r}
#Removes heights where h < 200 is false
not_big <- h < 200
h[not_big]
```
```{r}
length(h)
length(h[not_big])
```
```{r}
hist(h[not_big])
```

```{r}
h[h < 10]
```

```{r}
length(h[h < 10])
```

```{r}
h_kept <- h[(h >= 50) & (h <= 200)]
```

```{r}
hist(h_kept)
```

```{r}
h_cm1 <- h_kept[h_kept < 100] * 2.54
h_cm2 <- h_kept[h_kept >= 100]

h_cm <- c(h_cm1, h_cm2)
```
```{r}
h_cm
```

```{r}
hist(h_cm)
```
#### Histogram Breaks
```{r}
hist(h_cm, breaks = c(100))
hist(h_cm, breaks = c(10))
```

### Categorial Variables

```{r}
heights$sex
```
```{r}
table(heights$sex)
```
```{r}
# prop table
prop.table(table(heights$sex))
```
```{r}
s <- heights$sex

h[s == "Female"]
```
```{r}
#dplyer
df <- filter(heights, height >= 50, height <= 200)
#if height < 100; multiply by 2.54, otherwise leave it alone
#Put it in new col called scaled_height
df2 <- mutate(df, scaled_height = ifelse(height < 100, 2.54 * height, height))
```
```{r}
hist(df2$scaled_height)
```
```{r}
group_by(df2, sex)
```
```{r}
# Mean height of df2 groups by sex
# Conditional Mean
summarize(group_by(df2, sex), mean(scaled_height))
```

### ggplot
```{r}
#ggplot
ggplot(df2) + geom_histogram(aes(x=scaled_height, fill=sex))
```
```{r}
#Distributions by sex
ggplot(df2) + geom_histogram(aes(x=scaled_height)) + facet_grid(~ sex)
```


## Lecture 2: 8-28

```{r}
survey1 = read_csv("survey1.csv")

glimpse(survey1)
```

### Dataframe
A container of a bunch of vectors

```{r}
nrow(survey1)
ncol(survey1)
```

```{r}
apropos("rows")
```

```{r}
summary(survey1)
```

```{r}
colnames(survey1) <- c('timestamp', 'sex', 'height')

survey1$height
mean(survey1$height)
sd(survey1$height)
median(survey1$height)

#first element
survey1$height[1]

#last element
survey1$height[length(survey1$height)]

#Access entry > 70
mask <- survey1$height > 70
survey1$height[mask]
mean(mask)
```

### Cleaning Data

```{r}
#sorted entris of survey$heights
sort(survey1$height)
```

```{r}
my_data = c(1,2,3,8,-1)
my_data < 0
ifelse(my_data < 0, "neg", "pos")
```

```{r}
mean(c(1, NA, 3), na.rm=T)
```

### dplyr

#### filter

```{r}
filter(survey1, height == 70)
```

#### Sorting with arrange()

```{r}
##ascending by default, use desc for descending
arrange(survey1, desc(height))
```

#### filtering columns with select()
```{r}
select(survey1, sex, height)
# or
select(survey1, -timestamp)
```

#### column operation with mutate()

```{r}
#creates new cols in df that are calculated w/ existing dfs

mutate(survey1, height_cm = height * 2.54)
```

#### Creating Pipelines

```{r}
survey1_final <- survey1 |>
    filter(between(height, 150, 200)) |>
    arrange(height) |>
    select(sex, height)

survey1_final
```

## Lecture 3: 9-2
```{r}
survey1 |>
    filter((height > 400) | between(height, 4, 7)) |>
    pluck("height") -> height_gpt

height_gpt
```

## Lecture 4: 9-4
```{r}
library(nycflights13)
flights
```

```{r}
#Which airport is busiest
flights |> group_by(origin) |> summarize(n=n())
count(flights, origin, dest)

#which month is busiest
flights |> group_by(month) |> summarize(n=n())

#top 5 busiest days
flights |> count(month, day) |> arrange(desc(n))

#least busiest days 5
flights |> count(year, month, day) |> top_n(5, -n)

```

```{r}
#Which carrier has highest delay

flights |> 
    group_by(carrier) |> 
    summarise(avg_delay = mean(dep_delay, na.rm = T)) |>
    arrange(-avg_delay)
```

### relational data

```{r}
airlines
```

#### left_join()
```{r}
flights |> 
    group_by(carrier) |> 
    summarise(avg_delay = mean(dep_delay, na.rm = T)) |>
    left_join(airlines, by = "carrier") |>
    arrange(-avg_delay)
```

```{r}

airports |> filter(faa == "DTW")

# Do ppl fly south in the winter?

flights |> 
    left_join(airports, by=c("dest" = "faa")) |>
    select(month, lat) |>
    group_by(month) |>
    summarize(mean_abs_lat = mean(abs(lat), na.rm = T))
```


## Lecture 5: 9-9

```{r}
load("spotify_mpd_001.RData")
playlist |> sample_frac(0.01)
```

```{r}
artist |> filter(id == 9019)
```

```{r}
track |> left_join(artist, by = c("artist_id" = "id"))
```
```{r}
colnames(track_attr)
```

```{r}
track |> inner_join(track_attr, by = c("id" = "track_id"))
```

```{r}
playlist
playlist_track
```
```{r}
track |> 
    left_join(playlist_track, by=c("id" = "track_id")) |>
    filter(playlist_id == "1196") |>
    left_join(playlist, by = c("playlist_id" = "id"))
```
```{r}
#How many playlists
nrow(playlist)

#How many songs does each playlist have
playlist$num_tracks |> median()

#or 
count(playlist_track, playlist_id)$n |> median()


#How many playlist does each song appear 
count(playlist_track, track_id) |> 
    left_join(track, by=c("track_id" = "id")) |>
    top_n(10, n) 


count(playlist_track, track_id) |> summarize(mean(n))


#When are playlists created
playlist |> count(modified_at) |> ggplot() + 
    geom_point(aes(x = modified_at, y = n))
```

#### Song Charts

```{r}

load("hot100_2017.RData")

hot100_2017
```
### Pivot
```{r}
#Find average rank
hot100_long <-
    hot100_2017 |> 
    pivot_longer(cols = starts_with("w"),
                names_prefix = "w",
                names_to = "week",
                values_to = "rank") |>
    mutate(week = as.integer(week)) |> print()
```
```{r}
flights |> count(month, origin) |>
    pivot_wider(names_from = origin, values_from = n)
```

## Lecture 6: 9-11
```{r}
library(lubridate)
wday("2025-10-1", label = T)
```
```{r}
#Are playlist morelikely to be created on weekends

playlist |> 
    mutate(wday = wday(modified_at, label = T)) |> 
    select(pid, modified_at, wday) |> count(wday) -> playlist_wdays

playlist_wdays

#Significance Test

playlist_wdays |> pluck("n") |> chisq.test()
```

```{r}
#Which artist appears most in playlists
playlist |> left_join(playlist_track, by = c("id" = "playlist_id")) |>
    select(pid, track_id) |>
    left_join(track, by = c("track_id" = "id")) |>
    distinct(pid, artist_id) |>
    left_join(artist, by = c("artist_id" = "id")) |>
    count(name) |> arrange(desc(n))
```

### combn()

```{r}
combn(c("Eminem", "Rihanna", "Dr. Dre"), 2)
```

### Which artist had the most top 100 hits 2017
#### String split

```{r}
str_split("Beyonce & Jay-Z", " & ")
str_split("Beyonce Featuring Jay-Z", " Featuring ")


hot100_2017_long |>
    mutate(artists = str_split(Artist, " (&|Featuring|x) ")) |>
    unnest(artists) |> 
    count(artists, sort=TRUE)
```

## Lecture 9-16 (come back to later)


## Lecture 9-25

```{r}
load("a2weather.RData")

colnames(a2weather)
```

```{r}
a2weather |>
  filter(month == 2, year == 1893) |>
  select(starts_with("VALUE")) |>
  select(26:31)
```

```{r}
a2weather_tidy
```

```{r}
a2weather_tidy |> count(year = year(date)) |> ggplot() + 
    geom_line(aes(x = year, y = n))

```

```{r}
#Daily Temperature
a2weather_tidy |> 
    filter(date >= today() - ddays(30)) |> 
    mutate(tmax = tmax * 1.8 + 32) |> 
    ggplot() + geom_line(aes(x = date, y = tmax))
```

```{r}
a2weather_tidy |>  
    mutate(month = floor_date(date, "year")) |>
    group_by(month) |>
    summarize(tmax = mean(tmax, rm.na = T)) |>
    ggplot(aes(x = month, y = tmax)) + 
    geom_line() + geom_smooth(method="lm") + 
    labs(
        title = "Monthly Avg Temp in A2",
        x = "Month",
        y = "temp (C)"
    )
```

#### Statistical Modeling

Y = f(x) + $\in$

Y = Outcome

f = model function

x = explainer

$\in$ = noise

### Fitting a linear regression model

```{r}
mdl <- lm(tmax ~ date, data = a2weather_tidy)
summary(mdl)
coef(mdl)["date"] * 365 * 100

summary(mdl)$r.squared
```

### Residuals
```{r}
library(modelr)

a2weather_tidy |>
    add_residuals(mdl) |>
    ggplot(aes(x = resid)) + 
    geom_histogram() +
    labs(
        title = "residuals from lin regression model",
        x = "residuals"
    ) 
```

```{r}

```

## Lecture 9-30



```{r}
load("weather.RData") 
a2weather
```


#### Seasonal Trends

```{r}
a2weather |> colnames()
p1 <- a2weather |> mutate(doy = yday(date)) |> 
    group_by(doy) |> 
    summarise(tmax = mean(tmax, na.rm = T)) |>
    ggplot() + 
    geom_line(aes(x = doy, y = tmax)) + 
    labs(
        title = "avg anual temp cycle in a2",
        x = "day of yr",
        y = "temp(C)"
    )

p1
```

```{r}
p1 + stat_function(fun = function(x) sin(x), color = "red")
```

```{r}
flights |> colnames()

flights |>
  group_by(origin, carrier) |>
  summarise(n = n())
```

```{r}
mdl <- lm(tmax ~ date, data = a2weather_tidy)
r_val <- sign(coef(mdl)[2]) * sqrt(summary(mdl)$r.squared)
r_val
```

```{r}
flights |>
    group_by(origin, carrier) |> 
    summarise(n = n())
```